{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_01 24 27 67_Expt_10_BatchAnalysis_Spark.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"0SJFlsgelhFF"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M5m3-JrtjOqd","executionInfo":{"status":"ok","timestamp":1650867270982,"user_tz":-330,"elapsed":74254,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"e4e0d9c6-1d8e-4608-9729-d8b2ac1410fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n","\u001b[K     |████████████████████████████████| 281.4 MB 35 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.3\n","  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 46.8 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=8021e8b06ac2b0758c58cc9a5ebab98dd391b4c30e86ead929db725d0c0ce184\n","  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n","The following additional packages will be installed:\n","  openjdk-8-jre-headless\n","Suggested packages:\n","  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n","  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n","  fonts-wqy-zenhei fonts-indic\n","The following NEW packages will be installed:\n","  openjdk-8-jdk-headless openjdk-8-jre-headless\n","0 upgraded, 2 newly installed, 0 to remove and 40 not upgraded.\n","Need to get 36.5 MB of archives.\n","After this operation, 143 MB of additional disk space will be used.\n","Selecting previously unselected package openjdk-8-jre-headless:amd64.\n","(Reading database ... 155501 files and directories currently installed.)\n","Preparing to unpack .../openjdk-8-jre-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n","Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n","Preparing to unpack .../openjdk-8-jdk-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n","Setting up openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n","Setting up openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"]}],"source":["!pip install pyspark\n","!pip install -U -q PyDrive\n","!apt install openjdk-8-jdk-headless -qq\n","!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n","!tar xf spark-3.2.1-bin-hadoop3.2.tgz"]},{"cell_type":"markdown","source":["## Setting Environment Variables"],"metadata":{"id":"NaOfWr7rmxYG"}},{"cell_type":"code","source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n","os.environ[\"PYTHONPATH\"] = \"%SPARK_HOME%\\python;%SPARK_HOME%\\python\\lib\\py4j-0.10.9.3-src.zip:%PYTHONPATH%\""],"metadata":{"id":"9ygdOF_OllPp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZUjUvjPcm4op","executionInfo":{"status":"ok","timestamp":1650867297074,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"fa54bf1d-3209-4dd5-e5d9-34d92ea4831b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[".   .config\t spark-3.2.1-bin-hadoop3.2\n","..  sample_data  spark-3.2.1-bin-hadoop3.2.tgz\n"]}]},{"cell_type":"code","source":["import pyspark\n","print(pyspark.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrfu6YOKm6vH","executionInfo":{"status":"ok","timestamp":1650867299362,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"4ece9691-b329-41ff-afb5-95c6103f3610"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.2.1\n"]}]},{"cell_type":"code","source":["!pip install findspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Kbn8YJpm9Ga","executionInfo":{"status":"ok","timestamp":1650867304194,"user_tz":-330,"elapsed":3058,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"50833036-b071-4528-bf8c-5273d351ac91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting findspark\n","  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n","Installing collected packages: findspark\n","Successfully installed findspark-2.0.1\n"]}]},{"cell_type":"code","source":["import findspark\n","findspark.init() \n","findspark.find()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Ie47n3y9m-5G","executionInfo":{"status":"ok","timestamp":1650867306126,"user_tz":-330,"elapsed":10,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"6ab2efd1-e1e6-4c00-b9c6-346eb29b5540"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/spark-3.2.1-bin-hadoop3.2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# Word Count Program using an article"],"metadata":{"id":"VyUOSz5fnF1D"}},{"cell_type":"markdown","source":["### Setting the SparkContext"],"metadata":{"id":"9BK_M2l7nOsr"}},{"cell_type":"code","source":["from pyspark import SparkConf, SparkContext\n","from pyspark import SparkFiles\n","conf = SparkConf().setMaster(\"local\").setAppName(\"word-counts\")\n","sc = SparkContext(conf=conf)\n","sc.addFile(\"https://raw.githubusercontent.com/sreekeshiyer/dmbi_aids_datasets/main/Machine_Learning_Wikipedia.txt\")"],"metadata":{"id":"9MSKOJobnA10"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Setting up the data"],"metadata":{"id":"VmQv38JynU6O"}},{"cell_type":"code","source":["article = sc.textFile(\"file://\"+SparkFiles.get(\"Machine_Learning_Wikipedia.txt\"))\n","article.collect()[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LX7OzY-onRKY","executionInfo":{"status":"ok","timestamp":1650867327948,"user_tz":-330,"elapsed":2676,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"0dfb00df-f08e-473d-c710-0f3f00953518"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Machine learning',\n"," 'Machine learning (ML) is the study of computer algorithms that can improve automatically through experience and by the use of data.[1] It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so.[2] Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.[3]',\n"," '',\n"," 'A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.[5][6] Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.[7][8] In its application across business problems, machine learning is also referred to as predictive analytics.',\n"," '',\n"," 'Overview',\n"," 'Learning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in the future. These inferences can be obvious, such as \"since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well\". They can be nuanced, such as \"X% of families have geographically separate species with color variants, so there is a Y% chance that undiscovered black swans exist\".[9]',\n"," '',\n"," \"Machine learning programs can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks. For simple tasks assigned to computers, it is possible to program algorithms telling the machine how to execute all steps required to solve the problem at hand; on the computer's part, no learning is needed. For more advanced tasks, it can be challenging for a human to manually create the needed algorithms. In practice, it can turn out to be more effective to help the machine develop its own algorithm, rather than having human programmers specify every needed step.[10]\",\n"," '']"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["### Preprocessing\n","Remove Punctuation and Transform All Words to Lowercase.\n","To exclude punctuation values and convert all words to lowercase, we wrote a function like the one below."],"metadata":{"id":"T9o9Z1h2wpwX"}},{"cell_type":"code","source":["def lower_clean_str(x):\n","  punc='!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-'\n","  lowercased_str = x.lower()\n","  for ch in punc:\n","    lowercased_str = lowercased_str.replace(ch, '')\n","  return lowercased_str"],"metadata":{"id":"5nClBBiGwjMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["article = article.map(lower_clean_str)"],"metadata":{"id":"GVfswL3Aw6SN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We use split function to separate the words in all lines ."],"metadata":{"id":"XkoyHzoFxaan"}},{"cell_type":"code","source":["article=article.flatMap(lambda satir: satir.split(\" \"))"],"metadata":{"id":"TQmBQp0RxZsJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We do a filtering below to exclude whitespaces."],"metadata":{"id":"1dsHkOPExjst"}},{"cell_type":"code","source":["article = article.filter(lambda x:x!='')"],"metadata":{"id":"ExyCOip2xjb9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Getting word count"],"metadata":{"id":"ee6cQrbO0Osn"}},{"cell_type":"code","source":["article_count=article.map(lambda  word:(word,1))\n","article_count.take(4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBVPUXjtnWHF","executionInfo":{"status":"ok","timestamp":1650867341747,"user_tz":-330,"elapsed":1426,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"746a5610-a429-4ca9-cfb8-a5a7611f362c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('machine', 1), ('learning', 1), ('machine', 1), ('learning', 1)]"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["Apply ReduceByKey to find frequent words"],"metadata":{"id":"Dh9thU4ix0JP"}},{"cell_type":"code","source":["article_count_RBK=article_count.reduceByKey(lambda x,y:(x+y)).sortByKey()"],"metadata":{"id":"ESD-6rJLxr6P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["article_count_RBK.take(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OgPqRjTb0o4-","executionInfo":{"status":"ok","timestamp":1650867342430,"user_tz":-330,"elapsed":691,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"91572327-0692-4b3a-9670-ad13e964a93b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('1', 2),\n"," ('10', 2),\n"," ('10000', 1),\n"," ('13', 1),\n"," ('1959', 1),\n"," ('1960s', 1),\n"," ('1970s', 1),\n"," ('197316', 1),\n"," ('1980', 1),\n"," ('1980s', 1)]"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["sort the most frequent words in descending order."],"metadata":{"id":"D-Zod9L0yJ8h"}},{"cell_type":"code","source":["article_count_RBK=article_count_RBK.map(lambda x:(x[1],x[0]))"],"metadata":{"id":"BVyAvs4eyFAe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["article_count_RBK.take(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Nq2E6jByNbq","executionInfo":{"status":"ok","timestamp":1650867342432,"user_tz":-330,"elapsed":14,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"d595bb76-7cf1-4b47-9339-053aa7dde9ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(2, '1'), (2, '10'), (1, '10000'), (1, '13'), (1, '1959')]"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["article_count_RBK.sortByKey(False).take(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPQ45gyHyS7h","executionInfo":{"status":"ok","timestamp":1650867342432,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"a03d9d7e-75e1-4087-ee74-cbba7aea03c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(363, 'the'),\n"," (241, 'of'),\n"," (230, 'a'),\n"," (217, 'learning'),\n"," (212, 'to'),\n"," (185, 'and'),\n"," (178, 'in'),\n"," (129, 'is'),\n"," (124, 'machine'),\n"," (101, 'data')]"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["# Word Count Program using Songs Dataset"],"metadata":{"id":"jlZgzyKY1YeG"}},{"cell_type":"code","source":["import sys\n","\n","from operator import add\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import Tokenizer\n","from pyspark.ml.feature import StopWordsRemover\n","import pyspark.sql.functions as f\n","\n","spark = SparkSession\\\n","  .builder \\\n","  .appName(\"PythonWordCount\") \\\n","  .getOrCreate()\n","\n","spark.sparkContext.addFile(\"https://raw.githubusercontent.com/sreekeshiyer/dmbi_aids_datasets/main/billboard_lyrics_1964-2015.csv\")\n","\n","data = spark.read.csv(\"file://\"+SparkFiles.get(\"billboard_lyrics_1964-2015.csv\"), header=True, inferSchema= True)\n","\n","print('############ CSV extract:')\n","data.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KPot20BgJgr3","executionInfo":{"status":"ok","timestamp":1650867542281,"user_tz":-330,"elapsed":5548,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"d4b77105-8588-44a0-bd16-4a7afb6b22e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["############ CSV extract:\n","+----+--------------------+--------------------+----+--------------------+------+\n","|Rank|                Song|              Artist|Year|              Lyrics|Source|\n","+----+--------------------+--------------------+----+--------------------+------+\n","|   1|         wooly bully|sam the sham and ...|1965|sam the sham misc...|     3|\n","|   2|i cant help mysel...|           four tops|1965| sugar pie honey ...|     1|\n","|   3|i cant get no sat...|  the rolling stones|1965|                    |     1|\n","|   4| you were on my mind|             we five|1965| when i woke up t...|     1|\n","|   5|youve lost that l...|the righteous bro...|1965| you never close ...|     1|\n","|   6|            downtown|        petula clark|1965| when youre alone...|     1|\n","|   7|                help|         the beatles|1965|help i need someb...|     3|\n","|   8|cant you hear my ...|     hermans hermits|1965|carterlewis every...|     5|\n","|   9|crying in the chapel|       elvis presley|1965| you saw me cryin...|     1|\n","|  10|             my girl|     the temptations|1965|ive got sunshine ...|     3|\n","|  11|      help me rhonda|      the beach boys|1965|well since she pu...|     3|\n","|  12|    king of the road|        roger miller|1965| trailer for sale...|     1|\n","|  13|the birds and the...|         jewel akens|1965|let me tell ya bo...|     3|\n","|  14|hold me thrill me...|          mel carter|1965| hold me hold me ...|     1|\n","|  15|             shotgun|junior walker  th...|1965|i said ̢shotgun s...|     3|\n","|  16|      i got you babe|         sonny  cher|1965|they say were you...|     3|\n","|  17|   this diamond ring|gary lewis  the p...|1965|who wants to buy ...|     3|\n","|  18|        the in crowd|   ramsey lewis trio|1965|        instrumental|     3|\n","|  19|mrs brown youve g...|     hermans hermits|1965| mrs brown youve ...|     1|\n","|  20|stop in the name ...|        the supremes|1965| stop in the name...|     1|\n","+----+--------------------+--------------------+----+--------------------+------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["# Count and group word frequencies on the column Lyrics, when splitted by space comma\n","data.withColumn('word', f.explode(f.split(f.col('Lyrics'), ' '))) \\\n","  .groupBy('word') \\\n","  .count() \\\n","  .sort('count', ascending=False) \\\n","  .show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6VtwfykaJqVd","executionInfo":{"status":"ok","timestamp":1650867551108,"user_tz":-330,"elapsed":2963,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"379dac01-e847-4df4-975a-8cc14f167438"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-----+\n","|word|count|\n","+----+-----+\n","| you|64606|\n","|   i|56466|\n","| the|53451|\n","|  to|35752|\n","| and|32555|\n","|  me|31170|\n","|   a|29282|\n","|  it|25688|\n","|  my|22821|\n","|  in|18553|\n","|that|16151|\n","|  on|15814|\n","|your|15459|\n","|love|15283|\n","|  im|14278|\n","|  be|13004|\n","|  of|12825|\n","|    |12266|\n","| all|11895|\n","|dont|11587|\n","+----+-----+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["# To remove stop words (like \"I\", \"The\", ...), we need to provide arrays of words, not strings. Here we use APache Spark Tokenizer to do so.\n","# We create a new column to push our arrays of words\n","tokenizer = Tokenizer(inputCol=\"Lyrics\", outputCol=\"words_token\")\n","tokenized = tokenizer.transform(data).select('Rank','words_token')\n","\n","print('############ Tokenized data extract:')\n","tokenized.show()\n","\n","\n","# Once in arrays, we can use the Apache Spark function StopWordsRemover\n","# A new column \"words_clean\" is here as an output\n","remover = StopWordsRemover(inputCol='words_token', outputCol='words_clean')\n","data_clean = remover.transform(tokenized).select('Rank', 'words_clean')\n","\n","print('############ Data Cleaning extract:')\n","data_clean.show()\n","\n","\n","# Final step : like in the beginning, we can group again words and sort them by the most used\n","result = data_clean.withColumn('word', f.explode(f.col('words_clean'))) \\\n","  .groupBy('word') \\\n","  .count().sort('count', ascending=False) \\\n","\n","print('############ TOP20 Most used words in Billboard songs are:')\n","result.show()\n","\n","# Stop Spark Process\n","spark.stop()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZpT3LiMJtr1","executionInfo":{"status":"ok","timestamp":1650867557812,"user_tz":-330,"elapsed":6720,"user":{"displayName":"Sreekesh Iyer","userId":"07507984363083114269"}},"outputId":"ce08c48f-dffe-493e-eeec-42133555d69f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["############ Tokenized data extract:\n","+----+--------------------+\n","|Rank|         words_token|\n","+----+--------------------+\n","|   1|[sam, the, sham, ...|\n","|   2|[, sugar, pie, ho...|\n","|   3|                  []|\n","|   4|[, when, i, woke,...|\n","|   5|[, you, never, cl...|\n","|   6|[, when, youre, a...|\n","|   7|[help, i, need, s...|\n","|   8|[carterlewis, eve...|\n","|   9|[, you, saw, me, ...|\n","|  10|[ive, got, sunshi...|\n","|  11|[well, since, she...|\n","|  12|[, trailer, for, ...|\n","|  13|[let, me, tell, y...|\n","|  14|[, hold, me, hold...|\n","|  15|[i, said, ̢shotgu...|\n","|  16|[they, say, were,...|\n","|  17|[who, wants, to, ...|\n","|  18|      [instrumental]|\n","|  19|[, mrs, brown, yo...|\n","|  20|[, stop, in, the,...|\n","+----+--------------------+\n","only showing top 20 rows\n","\n","############ Data Cleaning extract:\n","+----+--------------------+\n","|Rank|         words_clean|\n","+----+--------------------+\n","|   1|[sam, sham, misce...|\n","|   2|[, sugar, pie, ho...|\n","|   3|                  []|\n","|   4|[, woke, morning,...|\n","|   5|[, never, close, ...|\n","|   6|[, youre, alone, ...|\n","|   7|[help, need, some...|\n","|   8|[carterlewis, eve...|\n","|   9|[, saw, crying, c...|\n","|  10|[ive, got, sunshi...|\n","|  11|[well, since, put...|\n","|  12|[, trailer, sale,...|\n","|  13|[let, tell, ya, b...|\n","|  14|[, hold, hold, ne...|\n","|  15|[said, ̢shotgun, ...|\n","|  16|[say, young, dont...|\n","|  17|[wants, buy, diam...|\n","|  18|      [instrumental]|\n","|  19|[, mrs, brown, yo...|\n","|  20|[, stop, name, lo...|\n","+----+--------------------+\n","only showing top 20 rows\n","\n","############ TOP20 Most used words in Billboard songs are:\n","+-----+-----+\n","| word|count|\n","+-----+-----+\n","| love|15283|\n","|   im|14278|\n","| dont|11587|\n","| know|11166|\n","| like|10949|\n","|   oh| 9736|\n","| baby| 9098|\n","|  got| 8289|\n","|  get| 8265|\n","|     | 7982|\n","|youre| 6592|\n","| yeah| 6259|\n","| want| 6214|\n","|   go| 6105|\n","| make| 5520|\n","|  one| 5412|\n","| cant| 5338|\n","|  see| 5264|\n","| time| 5176|\n","|  let| 4927|\n","+-----+-----+\n","only showing top 20 rows\n","\n"]}]}]}